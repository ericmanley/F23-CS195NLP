{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C192SOmJS6lw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CS 195: Natural Language Processing\n",
    "## More On Dataset Organization\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ericmanley/f23-CS195NLP/blob/main/F2_1_MoreOnDatasets.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "\n",
    "Hugging Face *Load a dataset from the Hub tutorial*: https://huggingface.co/docs/datasets/load_hub\n",
    "\n",
    "Hugging Face *dataset features doc*: https://huggingface.co/docs/datasets/about_dataset_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/000794593/Library/Python/3.10/lib/python/site-packages (4.32.0)\n",
      "Requirement already satisfied: datasets in /Users/000794593/Library/Python/3.10/lib/python/site-packages (2.14.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers) (1.23.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from datasets) (1.4.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: multiprocess in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas->datasets) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/000794593/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Frameworks/Python.framework/Versions/3.10/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#install what you need for this notebook\n",
    "import sys\n",
    "!{sys.executable} -m pip install transformers datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Picking up where we left off with datasets\n",
    "\n",
    "**Previously:** We had some code that looked like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item from the dataset: {'text': 'I‚Äôm really sorry about your situation :( Although I love the names Sapphira, Cirilla, and Scarlett!', 'labels': [25], 'id': 'eecwqtt'}\n",
      "Prediction from the model: {'label': 'remorse', 'score': 0.6783005595207214}\n",
      "\n",
      "Item from the dataset: {'text': \"It's wonderful because it's awful. At not with.\", 'labels': [0], 'id': 'ed5f85d'}\n",
      "Prediction from the model: {'label': 'admiration', 'score': 0.6606237888336182}\n",
      "\n",
      "Item from the dataset: {'text': 'Kings fan here, good luck to you guys! Will be an interesting game to watch! ', 'labels': [13], 'id': 'een27c3'}\n",
      "Prediction from the model: {'label': 'optimism', 'score': 0.549406111240387}\n",
      "\n",
      "Item from the dataset: {'text': \"I didn't know that, thank you for teaching me something today!\", 'labels': [15], 'id': 'eelgwd1'}\n",
      "Prediction from the model: {'label': 'gratitude', 'score': 0.9829797744750977}\n",
      "\n",
      "Item from the dataset: {'text': 'They got bored from haunting earth for thousands of years and ultimately moved on to the afterlife.', 'labels': [27], 'id': 'eem5uti'}\n",
      "Prediction from the model: {'label': 'neutral', 'score': 0.868577778339386}\n",
      "\n",
      "Item from the dataset: {'text': 'Thank you for asking questions and recognizing that there may be things that you don‚Äôt know or understand about police tactics. Seriously. Thank you.', 'labels': [15], 'id': 'ef2nq7i'}\n",
      "Prediction from the model: {'label': 'gratitude', 'score': 0.9893754720687866}\n",
      "\n",
      "Item from the dataset: {'text': 'You‚Äôre welcome', 'labels': [15], 'id': 'efdbh17'}\n",
      "Prediction from the model: {'label': 'gratitude', 'score': 0.9800959825515747}\n",
      "\n",
      "Item from the dataset: {'text': '100%! Congrats on your job too!', 'labels': [15], 'id': 'ef0ec3b'}\n",
      "Prediction from the model: {'label': 'admiration', 'score': 0.7933220267295837}\n",
      "\n",
      "Item from the dataset: {'text': 'I‚Äôm sorry to hear that friend :(. It‚Äôs for the best most likely if she didn‚Äôt accept you for who you are', 'labels': [24], 'id': 'ee8utmi'}\n",
      "Prediction from the model: {'label': 'remorse', 'score': 0.7268366813659668}\n",
      "\n",
      "Item from the dataset: {'text': 'Girlfriend weak as well, that jump was pathetic.', 'labels': [25], 'id': 'eeni74k'}\n",
      "Prediction from the model: {'label': 'sadness', 'score': 0.8615327477455139}\n",
      "Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# loading a dataset and a model\n",
    "emotions_dataset = load_dataset(\"go_emotions\", split=\"test\")\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"SamLowe/roberta-base-go_emotions\")\n",
    "\n",
    "number_to_try = 10\n",
    "\n",
    "#get predictions for the first number_to_try samples\n",
    "results = classifier(emotions_dataset[\"text\"][0:number_to_try])\n",
    "\n",
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "for idx in range(number_to_try):\n",
    "    \n",
    "    print(\"\\nItem from the dataset:\",emotions_dataset[idx])\n",
    "    print(\"Prediction from the model:\",results[idx])\n",
    "    \n",
    "    \n",
    "    predicted_label = results[idx][\"label\"]\n",
    "    actual_label_numeric = emotions_dataset[idx][\"labels\"][0] #this dataset returns a list of numeric labels\n",
    "    actual_label_name = emotions_dataset.features[\"labels\"].feature.int2str( actual_label_numeric ) #look up the name for this numeric label\n",
    "    \n",
    "    predicted_labels.append(predicted_label)\n",
    "    actual_labels.append( actual_label_name )\n",
    "    \n",
    "print(\"Accuracy:\",accuracy_score(actual_labels,predicted_labels) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## But how did we know how to do this?\n",
    "\n",
    "\n",
    "Note that the labels stored in the dataset have values like `[25]` or `[13]`\n",
    "\n",
    "but the model predicts `'remorse'` or `'optimism'`\n",
    "\n",
    "You can learn about some the of the things you can do with these class labels by looking at the documentation here: https://huggingface.co/docs/datasets/about_dataset_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'labels': Sequence(feature=ClassLabel(names=['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'], id=None), length=-1, id=None),\n",
       " 'id': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_dataset.features[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'], id=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_dataset.features['labels'].feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admiration',\n",
       " 'amusement',\n",
       " 'anger',\n",
       " 'annoyance',\n",
       " 'approval',\n",
       " 'caring',\n",
       " 'confusion',\n",
       " 'curiosity',\n",
       " 'desire',\n",
       " 'disappointment',\n",
       " 'disapproval',\n",
       " 'disgust',\n",
       " 'embarrassment',\n",
       " 'excitement',\n",
       " 'fear',\n",
       " 'gratitude',\n",
       " 'grief',\n",
       " 'joy',\n",
       " 'love',\n",
       " 'nervousness',\n",
       " 'optimism',\n",
       " 'pride',\n",
       " 'realization',\n",
       " 'relief',\n",
       " 'remorse',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'neutral']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_dataset.features['labels'].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'excitement'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_dataset.features['labels'].feature.names[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the documentation for each of these kinds of objects to figure out what they can do.\n",
    "\n",
    "https://huggingface.co/docs/datasets/v2.14.5/en/package_reference/main_classes#datasets.Value\n",
    "\n",
    "\n",
    "https://huggingface.co/docs/datasets/v2.14.5/en/package_reference/main_classes#datasets.Sequence\n",
    "\n",
    "\n",
    "https://huggingface.co/docs/datasets/v2.14.5/en/package_reference/main_classes#datasets.ClassLabel\n",
    "\n",
    "And you'll see that a `ClassLabel` has a function called `int2str`, so you can also find out which label goes with an int by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'excitement'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_dataset.features['labels'].feature.int2str(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problems with plugging in a different dataset and model\n",
    "\n",
    "Because of differences in the way that datasets organize their data, you may not be able to use the exact same code.\n",
    "\n",
    "Dataset: https://huggingface.co/datasets/papluca/language-identification\n",
    "\n",
    "Model: https://huggingface.co/papluca/xlm-roberta-base-language-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item from the dataset: {'labels': 'nl', 'text': 'Een man zingt en speelt gitaar.'}\n",
      "Prediction from the model: {'label': 'nl', 'score': 0.9956241250038147}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Value' object has no attribute 'feature'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m results[idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     24\u001b[0m actual_label_numeric \u001b[38;5;241m=\u001b[39m lang_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m][idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m#this dataset returns a list of numeric labels\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m actual_label_name \u001b[38;5;241m=\u001b[39m \u001b[43mlang_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241m.\u001b[39mint2str( actual_label_numeric ) \u001b[38;5;66;03m#look up the name for this numeric label\u001b[39;00m\n\u001b[1;32m     27\u001b[0m predicted_labels\u001b[38;5;241m.\u001b[39mappend(predicted_label)\n\u001b[1;32m     28\u001b[0m actual_labels\u001b[38;5;241m.\u001b[39mappend( actual_label_name )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Value' object has no attribute 'feature'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# loading a dataset and a model\n",
    "lang_dataset = load_dataset(\"papluca/language-identification\")\n",
    "classifier = pipeline(\"text-classification\", model=\"papluca/xlm-roberta-base-language-detection\")\n",
    "\n",
    "number_to_try = 10\n",
    "\n",
    "#get predictions for the first number_to_try samples\n",
    "results = classifier(lang_dataset[\"test\"][\"text\"][0:number_to_try])\n",
    "\n",
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "for idx in range(number_to_try):\n",
    "    \n",
    "    print(\"\\nItem from the dataset:\",lang_dataset[\"test\"][idx])\n",
    "    print(\"Prediction from the model:\",results[idx])\n",
    "    \n",
    "    \n",
    "    predicted_label = results[idx][\"label\"]\n",
    "    actual_label_numeric = lang_dataset[\"test\"][idx][\"labels\"][0] #this dataset returns a list of numeric labels\n",
    "    actual_label_name = lang_dataset[\"test\"].features[\"labels\"].feature.int2str( actual_label_numeric ) #look up the name for this numeric label\n",
    "    \n",
    "    predicted_labels.append(predicted_label)\n",
    "    actual_labels.append( actual_label_name )\n",
    "    \n",
    "print(\"Accuracy:\",accuracy_score(actual_labels,predicted_labels) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the item from the dataset has a key `'labels'` with the value `'nl'`\n",
    "\n",
    "and the prediction has a key `'label'` with the value `'nl'`\n",
    "\n",
    "These already match, so we can compare them directly - we don't need to extract the numeric value and then look up which name it represents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item from the dataset: {'labels': 'nl', 'text': 'Een man zingt en speelt gitaar.'}\n",
      "Prediction from the model: {'label': 'nl', 'score': 0.9956241250038147}\n",
      "\n",
      "Item from the dataset: {'labels': 'nl', 'text': 'De technologisch geplaatste Nasdaq Composite Index .IXIC daalde met 25,36 punten, of 1,53 procent, tot 1.628,26.'}\n",
      "Prediction from the model: {'label': 'nl', 'score': 0.9958615899085999}\n",
      "\n",
      "Item from the dataset: {'labels': 'es', 'text': 'Es muy resistente la parte trasera r√≠gida y los laterales de silicona para evitar ara√±ar el metal. Muy buena'}\n",
      "Prediction from the model: {'label': 'es', 'score': 0.992653489112854}\n",
      "\n",
      "Item from the dataset: {'labels': 'it', 'text': '\"In tanti modi diversi, l\\'abilit√† artistica dei musicisti neri ha trasmesso l\\'esperienza dei neri americani nel corso della nostra storia\", ha detto Bush.'}\n",
      "Prediction from the model: {'label': 'it', 'score': 0.9956134557723999}\n",
      "\n",
      "Item from the dataset: {'labels': 'ar', 'text': 'ŸÖŸÜÿ≠ÿØÿ± ŸäŸàÿßÿ¨Ÿá ÿßŸÑÿπÿØŸäÿØ ŸÖŸÜ ÿßŸÑŸÜŸÇÿßÿ¥ÿßÿ™ ÿßŸÑŸÖÿ™ÿ¨ŸáŸá ÿ•ÿ≤ÿßÿ° ÿßŸÑŸÇÿ∂ÿßŸäÿß ÿßŸÑÿ™Ÿâ ÿ™ÿ±ÿ™ÿ®ÿ∑ ÿ®ÿßŸÑÿ•ÿ¨Ÿáÿßÿ∂  .'}\n",
      "Prediction from the model: {'label': 'ar', 'score': 0.9939490556716919}\n",
      "\n",
      "Item from the dataset: {'labels': 'ru', 'text': '–ß–µ—Ä–µ–∑ –∫–∞–∂–¥—ã–µ —Å—Ç–æ –≥—Ä–∞–¥—É—Å–æ–≤ –ø—è—Ç–Ω–∞ –∫—Ä–∞—Å–∫–∏ –º–µ–Ω—è—é—Ç —Å–≤–æ–π —Ü–≤–µ—Ç, –æ–Ω–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –∫—Ä–∞—Å–Ω–æ–π –∏ –∏–∑–º–µ–Ω–∏—Ç—å —Ü–≤–µ—Ç –Ω–∞ —Å–∏–Ω–∏–π.'}\n",
      "Prediction from the model: {'label': 'ru', 'score': 0.9946050047874451}\n",
      "\n",
      "Item from the dataset: {'labels': 'tr', 'text': 'S√∂zl√ºƒü√ºn yanƒ± sƒ±ra, ortalama modern okuyucu i√ßin yine de √ßok anla≈üƒ±lamaz nitelikte olmasa da dil bilgisi, √∂zellikle de s√∂z dizimi kurallarƒ± da bir nebze deƒüi≈üti.'}\n",
      "Prediction from the model: {'label': 'tr', 'score': 0.9953035116195679}\n",
      "\n",
      "Item from the dataset: {'labels': 'nl', 'text': 'Verschillende mensen op motorfietsen op een marktplein.'}\n",
      "Prediction from the model: {'label': 'nl', 'score': 0.9958749413490295}\n",
      "\n",
      "Item from the dataset: {'labels': 'fr', 'text': 'Bonjour, Le produit est conforme √† la description, reste a voir la dur√©e de vie des cartouches Voila pour les commentaires'}\n",
      "Prediction from the model: {'label': 'fr', 'score': 0.9871856570243835}\n",
      "\n",
      "Item from the dataset: {'labels': 'es', 'text': 'No funciona lo he devuelto, no hace nada'}\n",
      "Prediction from the model: {'label': 'es', 'score': 0.993526816368103}\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# loading a dataset and a model\n",
    "lang_dataset = load_dataset(\"papluca/language-identification\")\n",
    "classifier = pipeline(\"text-classification\", model=\"papluca/xlm-roberta-base-language-detection\")\n",
    "\n",
    "number_to_try = 10\n",
    "\n",
    "#get predictions for the first number_to_try samples\n",
    "results = classifier(lang_dataset[\"test\"][\"text\"][0:number_to_try])\n",
    "\n",
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "for idx in range(number_to_try):\n",
    "    \n",
    "    print(\"\\nItem from the dataset:\",lang_dataset[\"test\"][idx])\n",
    "    print(\"Prediction from the model:\",results[idx])\n",
    "    \n",
    "    \n",
    "    predicted_label = results[idx][\"label\"]\n",
    "    actual_label = lang_dataset[\"test\"][idx][\"labels\"] #this dataset returns labels as strings\n",
    "    \n",
    "    predicted_labels.append(predicted_label)\n",
    "    actual_labels.append( actual_label )\n",
    "    \n",
    "print(\"Accuracy:\",accuracy_score(actual_labels,predicted_labels) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Another dataset\n",
    "\n",
    "Here's another dataset that is also different: https://huggingface.co/datasets/tweet_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dataset = load_dataset(\"tweet_eval\", \"emoji\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 45000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 50000\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_test_dataset = tweet_dataset[\"test\"]\n",
    "tweet_test_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Welcome to New York! @ Times Square, New York City', 'label': 5}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_test_dataset[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one seems to store the labels as numbers. \n",
    "\n",
    "Note that it isn't a list with a number in it like it was for `go_emotions`\n",
    "\n",
    "It's also `'label'` instead of `'labels'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I‚Äôm really sorry about your situation :( Although I love the names Sapphira, Cirilla, and Scarlett!',\n",
       " 'labels': [25],\n",
       " 'id': 'eecwqtt'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What do the numbers represent the tweet dataset?\n",
    "\n",
    "Let's look the data set's features attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['‚ù§', 'üòç', 'üòÇ', 'üíï', 'üî•', 'üòä', 'üòé', '‚ú®', 'üíô', 'üòò', 'üì∑', 'üá∫üá∏', '‚òÄ', 'üíú', 'üòâ', 'üíØ', 'üòÅ', 'üéÑ', 'üì∏', 'üòú'], id=None)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_test_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['‚ù§', 'üòç', 'üòÇ', 'üíï', 'üî•', 'üòä', 'üòé', '‚ú®', 'üíô', 'üòò', 'üì∑', 'üá∫üá∏', '‚òÄ', 'üíú', 'üòâ', 'üíØ', 'üòÅ', 'üéÑ', 'üì∏', 'üòú'], id=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_test_dataset.features['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one organizes it differently!\n",
    "\n",
    "Compare to our `go_emotions` example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(names=['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral'], id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_dataset.features[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since the tweet data already has a `ClassLabel` here - not a `Sequence` with `feature=ClassLabel`, we can proceed directly to getting the string from the int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'üòä'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_test_dataset.features['label'].int2str(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Adapting our code to make it work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item from the dataset: {'text': 'en Pelham Parkway', 'label': 2} üòÇ\n",
      "Prediction from the model: {'label': 'üòç', 'score': 0.1873828023672104}\n",
      "\n",
      "Item from the dataset: {'text': 'The calm before...... | w/ sofarsounds @user | : B. Hall.......#sofarsounds‚Ä¶', 'label': 10} üì∑\n",
      "Prediction from the model: {'label': 'üì∑', 'score': 0.65936678647995}\n",
      "\n",
      "Item from the dataset: {'text': 'Just witnessed the great solar eclipse @ Tampa, Florida', 'label': 6} üòé\n",
      "Prediction from the model: {'label': 'üòé', 'score': 0.17400723695755005}\n",
      "\n",
      "Item from the dataset: {'text': 'This little lady is 26 weeks pregnant today! Excited for baby Cam to come! @ Springfield,‚Ä¶', 'label': 1} üòç\n",
      "Prediction from the model: {'label': 'üòç', 'score': 0.4535968601703644}\n",
      "\n",
      "Item from the dataset: {'text': 'Great road trip views! @ Shartlesville, Pennsylvania', 'label': 16} üòÅ\n",
      "Prediction from the model: {'label': 'üòç', 'score': 0.5469061136245728}\n",
      "\n",
      "Item from the dataset: {'text': 'CHRISTMAS DEALS BUY ANY 3 SMALL POMADES 1.5 OR 1.7 OZ RECEIVE THE F&amp;S COLLECTOR TIN &amp; COMB‚Ä¶', 'label': 17} üéÑ\n",
      "Prediction from the model: {'label': 'üéÑ', 'score': 0.8079564571380615}\n",
      "\n",
      "Item from the dataset: {'text': 'the #sisterstunt was mad real last night #MiaStaxxx #AndreaStaxxx #denverqueen #staxxxlife‚Ä¶', 'label': 4} üî•\n",
      "Prediction from the model: {'label': 'üòÇ', 'score': 0.8102162480354309}\n",
      "\n",
      "Item from the dataset: {'text': \"I'm starting to love shooting in the dark #brandonwolfel @ New York, New York\", 'label': 10} üì∑\n",
      "Prediction from the model: {'label': 'üì∑', 'score': 0.2671496272087097}\n",
      "\n",
      "Item from the dataset: {'text': 'Let the sun shine through Ô∏è 5x5 Feet #oilpainting #oiloncanvas #acrylicpainting #acryliconcanvas‚Ä¶', 'label': 12} ‚òÄ\n",
      "Prediction from the model: {'label': '‚òÄ', 'score': 0.948815107345581}\n",
      "\n",
      "Item from the dataset: {'text': 'Still bitch im trill never been no fiend :@vibesbygallo #mustard @ Connecticut', 'label': 18} üì∏\n",
      "Prediction from the model: {'label': 'üì∑', 'score': 0.5090698599815369}\n",
      "Accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# loading a dataset and a model\n",
    "tweet_dataset = load_dataset(\"tweet_eval\", \"emoji\", split=\"test\")\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-emoji\")\n",
    "\n",
    "number_to_try = 10\n",
    "\n",
    "#get predictions for the first number_to_try samples\n",
    "results = classifier(tweet_dataset[\"text\"][0:number_to_try])\n",
    "\n",
    "predicted_labels = []\n",
    "actual_labels = []\n",
    "\n",
    "for idx in range(number_to_try):\n",
    "    \n",
    "    print(\"\\nItem from the dataset:\",tweet_dataset[idx],tweet_test_dataset.features['label'].int2str(tweet_dataset[idx]['label']))\n",
    "    print(\"Prediction from the model:\",results[idx])\n",
    "    \n",
    "    \n",
    "    predicted_label = results[idx][\"label\"]\n",
    "    actual_label_numeric = tweet_dataset[idx][\"label\"] #this dataset returns a list of numeric labels\n",
    "    actual_label_name = tweet_dataset.features[\"label\"].int2str( actual_label_numeric ) #look up the name for this numeric label\n",
    "    \n",
    "    predicted_labels.append(predicted_label)\n",
    "    actual_labels.append( actual_label_name )\n",
    "    \n",
    "print(\"Accuracy:\",accuracy_score(actual_labels,predicted_labels) )"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "authorship_tag": "ABX9TyOf2oi4GbgdvkO0orSdgZtQ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
